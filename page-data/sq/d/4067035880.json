{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"3-D Scene Reconstruction with SfM & Neural Rendering","tech":["COLMAP / SfM","NeRF","Open3D","PyTorch"],"github":"https://github.com/rigved-sanku/NeRF-Implementation-for-Efficient-3D-Scene-Reconstruction","external":"https://drive.google.com/file/d/191Jkv1Q44M3D3gIVyh1QFXB0p5yd0nXj/view"},"html":"<p>I built a pipeline that turns a set of photos into a full 3-D model you can view from any angle. First, I used <strong>Structure-from-Motion</strong> in COLMAP to find camera poses and a sparse point cloud. Next, I densified the geometry with Open3D and fed the results into a <strong>Neural Radiance Field (NeRF)</strong>, which learns how light flows through the scene and produces smooth, realistic renderings.</p>\n<p>The project taught me feature matching, bundle adjustment, point-cloud processing, and the basics of neural rendering while giving me plenty of practice with PyTorch and 3-D visualisation tools.</p>"}},{"node":{"frontmatter":{"title":"VIO for Drones","tech":["MSCKF","CNN / ResNet","LSTM + Attention","PyTorch","ROS","EuRoC Dataset"],"github":null,"external":"https://drive.google.com/file/d/1oHou6dvBSZXjW5Z-boLfd3GG388aZdY_/view"},"html":"<p>A hybrid <strong>SLAM-based Visual-Inertial Odometry (VIO)</strong> pipeline for autonomous UAVs that fuses classical and deep-learning methods. The front-end employs the <strong>Multi-State Constraint Kalman Filter (MSCKF)</strong> for geometrically consistent state updates, while a suite of CNN, ResNet, and LSTM-with-attention networks refines motion estimates from raw images and IMU streams. On the EuRoC benchmark, the system delivers improvement in absolute-trajectory error over baseline VO/IO models.</p>"}},{"node":{"frontmatter":{"title":"Tesla Vision w/ Blender Visualization","tech":["Object Detection","Semantic Segmentation","Optical Flow","Pose Estimation","Blender","Pytorch","Python"],"github":null,"external":"https://drive.google.com/file/d/1oHou6dvBSZXjW5Z-boLfd3GG388aZdY_/view"},"html":"<p>Engineered comprehensive ADAS computer vision stack integrating DETIC for instance segmentation for traffic and vehicle lights,YOLO3D for 6D-pose estimation, UniDepth for depth estimation, Mask R-CNN for lane detection, RAFT optical flow for\nmovement analysis, OSX for 3D human mesh, rendering all elements dynamically in Blender for visualization like Tesla dashboard.</p>"}}]}}}