---
date: '2021-01-01'
title: 'English-German Language Translation using Attention-based Seq2Seq'
cover: './images/blistabloc.png' # include an attention heatmap or architecture diagram
github: 'https://github.com/rigved-sanku/NLP-Translation-Attention' # update if different
tech:
  - LSTM
  - Seq2Seq
  - Attention
  - NumPy
  - BLEU Score
---

Engineered LSTM-RNN and sequence-to-sequence (**seq2seq**) models with attention mechanisms from scratch using **NumPy**. Implemented backpropagation through time (BPTT) and trained the model to perform English-German translation. This project deepened my understanding of **encoderâ€“decoder architectures**, **gradient flow**, and how attention improves alignment in machine transla
